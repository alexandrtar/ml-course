import cv2
import numpy as np
from ultralytics import YOLO
import matplotlib.pyplot as plt
import requests
from io import BytesIO
from PIL import Image
import os

def download_test_image():
    """Ğ¡ĞºĞ°Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ğ¾Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ Ñ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞºĞ¾Ğ¼"""
    print("ğŸ“¥ Downloading test image with human...")
    
    # URL Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ñ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞºĞ¾Ğ¼
    urls = [
        "https://raw.githubusercontent.com/ultralytics/ultralytics/main/ultralytics/assets/bus.jpg",
        "https://raw.githubusercontent.com/ultralytics/yolov5/master/data/images/zidane.jpg"
    ]
    
    for url in urls:
        try:
            response = requests.get(url, timeout=10)
            if response.status_code == 200:
                image = Image.open(BytesIO(response.content))
                image = np.array(image)
                print(f"âœ… Downloaded image from {url}")
                return image
        except Exception as e:
            print(f"âŒ Failed to download from {url}: {e}")
            continue
    
    # Ğ•ÑĞ»Ğ¸ Ğ½Ğµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ ÑĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ, ÑĞ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ
    print("âš ï¸  Using fallback image...")
    return create_simple_human_image()

def create_simple_human_image():
    """Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ Ñ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞºĞ¾Ğ¼"""
    img = np.ones((512, 512, 3), dtype=np.uint8) * 255
    return img

def run_demo():
    print("ğŸ¯ YOLO Human Segmentation DEMO")
    print("=" * 50)
    
    try:
        # Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
        print("1. Loading YOLO model...")
        model = YOLO('yolov8n-seg.pt')
        print("   âœ… Model loaded")
        
        # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ğ¾Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ
        print("2. Getting test image...")
        image = download_test_image()
        print(f"   âœ… Image shape: {image.shape}")
        
        # Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµĞ¼ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ
        print("3. Running segmentation...")
        results = model(image, verbose=False)
        
        # ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ - Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞĞĞ¯ Ğ’Ğ•Ğ Ğ¡Ğ˜Ğ¯
        mask = np.zeros(image.shape[:2], dtype=np.float32)
        detections = []
        
        for result in results:
            # Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ Ğº bounding boxes
            if result.boxes is not None and len(result.boxes) > 0:
                boxes = result.boxes.xyxy.cpu().numpy()  # ĞšĞ¾Ğ¾Ñ€Ğ´Ğ¸Ğ½Ğ°Ñ‚Ñ‹ bbox
                classes = result.boxes.cls.cpu().numpy()  # ĞšĞ»Ğ°ÑÑÑ‹
                confidences = result.boxes.conf.cpu().numpy()  # Ğ£Ğ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸
                
                for i, (box, cls, conf) in enumerate(zip(boxes, classes, confidences)):
                    class_name = result.names[int(cls)]
                    detections.append((class_name, conf))
                    print(f"   âœ… Detected: {class_name} (confidence: {conf:.3f})")
            
            # ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¼Ğ°ÑĞ¾Ğº
            if result.masks is not None:
                for i, m in enumerate(result.masks):
                    mask_data = m.data[0].cpu().numpy()
                    # Ğ˜Ğ·Ğ¼ĞµĞ½ÑĞµĞ¼ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€ Ğ¼Ğ°ÑĞºĞ¸ Ğº Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ñƒ Ğ¸ÑÑ…Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ
                    mask_resized = cv2.resize(mask_data, (image.shape[1], image.shape[0]))
                    mask = np.logical_or(mask, mask_resized)
                print(f"   ğŸ­ Found {len(result.masks)} segmentation mask(s)")
        
        # Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
        print("4. Creating visualization...")
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # ĞÑ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ
        axes[0, 0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
        axes[0, 0].set_title('Original Image')
        axes[0, 0].axis('off')
        
        # ĞœĞ°ÑĞºĞ° ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸
        axes[0, 1].imshow(mask, cmap='gray')
        axes[0, 1].set_title('Segmentation Mask')
        axes[0, 1].axis('off')
        
        # ĞĞ°Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ Ğ¼Ğ°ÑĞºĞ¸
        axes[1, 0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
        if mask.sum() > 0:
            axes[1, 0].imshow(mask, cmap='jet', alpha=0.5)
            axes[1, 0].set_title('Mask Overlay')
        else:
            axes[1, 0].set_title('No Segmentation Found')
        axes[1, 0].axis('off')
        
        # Ğ˜Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ
        axes[1, 1].axis('off')
        info_text = "Detection Results:\n\n"
        if detections:
            for class_name, confidence in detections[:8]:  # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ 8
                info_text += f"{class_name}: {confidence:.3f}\n"
        else:
            info_text += "No objects detected\n\n"
            info_text += "Image might not contain detectable objects"
        
        axes[1, 1].text(0.1, 0.5, info_text, fontsize=12, va='center', 
                       bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
        
        plt.tight_layout()
        plt.savefig('quick_demo_result.png', dpi=150, bbox_inches='tight')
        plt.show()
        
        print(f"ğŸ“ Results saved to 'quick_demo_result.png'")
        
        # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºÑƒ Ğ¼Ğ°ÑĞºĞ¸
        if mask.sum() > 0:
            mask_coverage = (mask.sum() / (mask.shape[0] * mask.shape[1])) * 100
            print(f"ğŸ“Š Mask covers {mask_coverage:.1f}% of image")
        
    except Exception as e:
        print(f"âŒ Demo error: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    run_demo()