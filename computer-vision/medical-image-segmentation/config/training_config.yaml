# Training Configuration
training:
  batch_size: 8
  epochs: 100
  learning_rate: 0.001
  weight_decay: 0.0001
  early_stopping_patience: 15
  save_checkpoint_frequency: 5
  
  # Optimizer
  optimizer: "adam"
  scheduler: "reduce_lr_on_plateau"
  scheduler_patience: 10
  scheduler_factor: 0.5
  
  # Data
  image_size: [256, 256]
  num_workers: 4
  pin_memory: true
  shuffle: true
  
  # Augmentations
  augmentations:
    horizontal_flip: true
    vertical_flip: true  
    rotation_range: 15
    brightness_range: [0.8, 1.2]
    contrast_range: [0.8, 1.2]
    elastic_alpha: 50
    elastic_sigma: 5
    gaussian_noise: true

# Model Configuration
model:
  name: "UNet"
  in_channels: 1
  out_channels: 1
  features: [64, 128, 256, 512, 1024]
  dropout: 0.2
  activation: "relu"
  normalization: "batch_norm"

# Data Configuration
data:
  synthetic_samples: 1000
  train_ratio: 0.7
  val_ratio: 0.2
  test_ratio: 0.1
  random_seed: 42
  
  # Paths
  data_dir: "data/processed"
  raw_dir: "data/raw"
  output_dir: "outputs"

# Loss Configuration
loss:
  name: "combined"
  dice_weight: 0.7
  bce_weight: 0.3
  iou_weight: 0.0
  focal_weight: 0.0

# Experiment Tracking
tracking:
  use_mlflow: true
  use_wandb: false
  experiment_name: "medical_segmentation"
  run_name: "unet_baseline_${timestamp}"
  log_interval: 10
  
  # MLflow settings
  mlflow_tracking_uri: "mlruns"
  mlflow_experiment_name: "medical_segmentation"

# Inference Configuration
inference:
  confidence_threshold: 0.5
  device: "auto"
  batch_size: 16
  output_format: "numpy"